 \documentclass[a4paper,USenglish]{lipics-v2019}
 
 \usepackage[utf8]{inputenc}
 \usepackage{xspace}
 \usepackage{balance}
 \usepackage{amsmath,amsfonts,mathtools,amsthm}
 \usepackage{algorithmic}
 
 \usepackage{balance}
 \usepackage{blindtext}
 \usepackage{amsthm,amsmath,array,colortbl,graphicx,multirow}
 \usepackage{comment}
 \usepackage{balance}
 \usepackage{tikz}
 \usepackage{amsmath}
 \usetikzlibrary{patterns} %
 \usepackage{algorithm}
 \usepackage[font={footnotesize}]{subcaption}
 \usepackage[font={footnotesize}]{caption}
 \usepackage{breakcites}
 \usepackage{booktabs}
 \usepackage{diagbox}
 \usepackage{xcolor}
 \usepackage{colortbl}
 \usepackage{cleveref}
 \usepackage{enumitem}
 
 \mathchardef\mhyphen="2D
 
 \title{Cascade Hypothesis for Dynamic Balanced Graph Partitioning}
 \author{x}{y}{}{}{}
 \authorrunning{Cascade Hypothesis}

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
 %  our macros start
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
 
 \newcommand{\OPT}{\textsf{OPT}\xspace}
 \newcommand{\ONL}{\textsf{ONL}\xspace}
 \newcommand{\DET}{\textsf{CAS}\xspace}
 \newcommand{\ALG}{\textsf{ALG}\xspace}
 \newcommand{\PPL}{\textsf{PPL}\xspace}
 \newcommand{\OBRP}{BRP}
 \newcommand{\PPOBRP}{PP-BRP}
 \newcommand{\dist}{\textsf{dist}}
 \newcommand{\TAlg}{{\ensuremath{\textsf{CAS}}}\xspace}
 
 \newcommand{\comm}{\textsc{comm}}
 \newcommand{\OFF}{\textsc{Off}\xspace}
 \newcommand{\Rep}{\textsc{Rep}}
 
 
 
 
 \newtheorem{task}{Task}
 \newtheorem{fact}{Fact}
 \newtheorem{hypothesis}{Hypothesis}
 \newtheorem{rem}{Remark}
 \newtheorem{observation}{Observation}
 \newtheorem{property}{Property}
 
 
 \DeclarePairedDelimiter\pair{(}{)}
 \DeclarePairedDelimiter\set{\{}{\}}
 
 \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
 \DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
 
 \newcommand\mahmoud[1]{\color{orange}\textbf{Mahmoud: #1~}\color{black}}
 \newcommand\stefan[1]{\color{blue}\textbf{Stefan: #1}\color{black}}
 \newcommand\maciek[1]{\color{brown}\textbf{(Maciek: #1)}\color{black}}
 %\newcommand\mahmoud[1]{}
 %\newcommand\stefan[1]{}
 %\newcommand\maciek[1]{}
 
 \newcommand{\todo}[1]{\noindent\color{brown}{todo: #1}\color{black}}

\begin{document}

\maketitle

\section{Problem definition of Dynamic Balanced Graph Partitioning}


\noindent
\textbf{Nodes and clusters.} There is a set of $n$ nodes, initially distributed arbitrarily
across $\ell$~clusters, each of size~$k$. We call two nodes~$u,v\in V$
\emph{collocated} if they are in the same cluster.

\noindent
\textbf{Input sequence.} An input to the problem is a sequence of communication requests $\sigma =
(u_1,v_1),$ $(u_2,v_2),$ $(u_3,v_3), \ldots$, where pair $(u_t,v_t)$ means that
the nodes $u_t,v_t$ exchange a fixed amount of data. At any time~$t
$, an algorithm needs to serve the~communication
request~$(u_t,v_t)$.


\noindent
\textbf{Reconfigurations.} Right before serving the request, the algorithm
can move nodes between clusters.
The nodes fit perfectly into the clusters,
i.e.,~$n=k\cdot \ell$. Due to cluster capacity
constraints, a node can never be migrated alone, but it must be \emph{swapped}
with another node at a cost of~$2 \cdot \alpha$. We also assume that when an
algorithm wants to migrate more than two nodes, this has to be done using
several swaps, each involving two nodes.

\noindent
\textbf{The cost.} We assume that
a~communication request between two collocated nodes (i.e., placed on the same
server) costs 0. The cost of a~communication request between two nodes located in different clusters is
1, and the cost of migrating a node from one cluster to another
is~$\alpha \geq 1$, where $\alpha$ is a parameter (an~integer). 
The total cost of an algorithm \ALG, consisting of communication plus migration
cost.

\subsection{Online algorithms and competitive analysis}

The input to the problem is revealed one-by-one, in online fashion. Upon seeing
a request, the algorithm must serve it without the knowledge of future requests
(although prior to serving the request, it can reconfigure the nodes).


We measure
the performance of an online algorithm by comparing to the performance of an optimal offline
algorithm. Formally, let~$\ONL(\sigma)$, resp.~$\OPT(\sigma)$, be the cost
incurred by an online algorithm \ONL, resp.~by an optimal offline
algorithm \OPT, for a given sequence of requests~$\sigma$. In contrast to \ONL, which learns the~requests one-by-one as
it serves them, \OPT has complete knowledge of the entire request
sequence~$\sigma$ \emph{ahead of~time}. The goal is to design online repartitioning
algorithms that provide worst-case guarantees. In particular, $\ONL$ is said
to be \emph{$\rho$-competitive} if there is a constant $\beta$, such that for any
input sequence~$\sigma$ it holds that
\[
	\ONL(\sigma) \leq \rho \cdot \OPT(\sigma) + \beta.
\]
Note that $\beta$ cannot depend on input $\sigma$ but can depend on other
parameters of the problem, such as the number of nodes or the number of clusters.
The minimum $\rho$ for which $\ONL$ is $\rho$-competitive is called the 
\emph{competitive ratio} of $\ONL$. 

\noindent
\textbf{Note on running time.}
Although it is vital to keep the running time of an online algorithm low, it is
not a strict requirement. In contrast to exact algorithms or approximation
algorithms, the running time of an online algorithm may be exponential.
The algorithmic challenge lies in making decisions without the knowledge of the
future.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The algorithm CAS}
\label{sec:upper}

We introduce $O(k^2
\cdot \ell^2)$-competitive deterministic algorithm \DET. At any time, \DET
serves a request, adjusts its internal structures (defined below)
accordingly and then possibly migrates some nodes. \DET operates in phases, and each
phase is analyzed separately. The first phase starts with the first request.

In a single phase, \DET maintains a helper structure: a complete graph on all
$\ell \cdot k$ nodes, with an edge present between each pair of nodes. We say
that a communication request is \emph{paid} (by \DET) if it occurs between
nodes from different clusters, and thus entails a cost for \DET. For each edge
between nodes $x$ and $y$, we define its weight~$w(x,y)$ to be the number of
paid communication requests between $x$ and~$y$ since the beginning of~the~current phase.

Whenever an edge weight reaches $\alpha$, it is called \emph{saturated}.
Throughout its execution, \DET maintains an invariant that saturated edges are inside clusters (i.e., two nodes of such edge are collocated). 
From the perspective of node placement, this means that each node of a~connected component of saturated edges must be collocated in a single cluster.

If a
request causes the corresponding edge to~become saturated,
we perform a \emph{reconfiguration} of nodes.
\DET computes a new placement of nodes (potentially for all of them), so that all
saturated edges are inside clusters.
If finding such placement
is not possible, node positions are not changed, the~current phase ends
with the current request, and a new phase begins with the next request.
Among all possible placements, \DET chooses the closest to the current
configuration. 

Note that there is only one new saturated edge at a~time, and all edge weights are reset to zero at the beginning of a phase.


\begin{theorem}
\DET is $O(k^2 \cdot \ell^2)$-competitive.
\label{th:detsqare}
\end{theorem}

\begin{proof}
We bound the costs of \DET and \OPT in a single phase. First, observe that
whenever an~edge weight reaches $\alpha$, its endpoint nodes will be collocated 
until the end of the phase, and therefore its weight is not
incremented anymore. Hence the weight of any edge is at most $\alpha$.

Second, observe that the graph induced by saturated edges always constitutes 
a~forest. Suppose that, at a time $t$,
two nodes $x$ and~$y$, which are not
connected by a~saturated edge, become connected by a path of saturated edges.
From that time onward, \DET stores them in a~single cluster. Hence, the
weight~$w(x,y)$ cannot increase at subsequent time points, and $(x,y)$ may
not become saturated. The forest property implies that the number of saturated
edges is smaller than $k \cdot \ell$.

The two observations above allow us to bound the cost of \DET in a single
phase. The number of reorganizations is at most the number of saturated edges,
i.e., at most~$k \cdot \ell$. As the cost associated with a single
reorganization is $O(k \cdot \ell \cdot \alpha)$, the total cost of all node
migrations in a single phase is at most $O(k^2 \cdot \ell^2 \cdot \alpha)$.
The communication cost itself is equal to the total weight of all edges, and
by the first observation, it is at most $\binom{k \cdot \ell}{2}
\cdot \alpha < k^2 \cdot \ell^2 \cdot \alpha$. Hence, for any phase $P$ (also
for the last one), it holds that $\DET(P) = O(k^2 \cdot \ell^2 \cdot \alpha)$.

Now we lower-bound the cost of \OPT on any phase $P$ but the last one. If \OPT
performs a~node swap in $P$, it pays $2 \cdot \alpha$. Otherwise its assignment of
nodes to clusters is fixed throughout~$P$. Recall that at the end of $P$, \DET
failed to reorganize the nodes. This means that for any static mapping of the
nodes to clusters (in particular the one chosen by \OPT), there is a~saturated inter-cluster edge. The communication cost over such an~edge incurred
by \OPT is at least $\alpha$ (it can be also strictly greater than~$\alpha$ as
the edge weight only counts the communication requests paid by \DET).

Therefore, the $\DET$-to-$\OPT$ cost ratio in any phase but the last one is at
most $O(k^2 \cdot \ell^2)$ and the cost of \DET on the last phase is at
most $O(k^2 \cdot \ell^2 \cdot \alpha)$. Hence,
$\DET(\sigma) \leq O(k^2 \cdot \ell^2) \cdot \OPT(\sigma) + O(k^2 \cdot
\ell^2 \cdot \alpha)$ for any input $\sigma$.
\end{proof}

\section{The cascade hypothesis.}

Upon receiving a request, an edge may become saturated, 
and \DET may perform a reconfiguration of its nodes.
The cascade hypothesis aims to bound the cost of a single reconfiguration performed by \DET.

\subsection{The cascade.}

Consider an edge saturation event that triggers a reconfiguration from a configuration $C_I$ to a configuration $C_F$.
Prior to the event, the two nodes $u,v$ of the new saturated edge were located in different clusters --- only paid requests increase the counter.
\DET collocates $u$ and $v$ in a single cluster, e.g. it may migrate $u$ to $v$'s cluster or migrate both $u$ and $v$ to a common cluster.

To collocate $u$ and $v$, we may need to additionally migrate other nodes.
This is due to the limited capacity of clusters, and also to keep saturated edges inside clusters.
    
The partition must be balanced at all times: each cluster must contain exactly $k$ nodes. If we migrate a single node $u$ from a cluster $A$ to a cluster $B$, we must (1) migrate another node to fill the place of $u$ in $A$, and (2) evict a node from $B$ to another cluster.

\DET keeps saturated edges inside clusters, hence a migration of a single node may entail migrations of other nodes.
If the migrated node $u$ is already connected with a saturated edge with another node $u'$, we must migrate both of them. In turn, $u'$ may have a saturated edge to yet another node. Precisely, to maintain the invariant, we must migrate nodes in groups that correspond to connected components in the graph of saturated edges.

We refer to the set of nodes inside a connected component in the graph of saturated edges as \emph{component}.
A saturation of an edge \emph{merges} two components.
Components are unsplittable --- their nodes must be collocated.
In each reconfiguration we must assure that each cluster contains exactly $k$ nodes, and to satisfy this condition, \DET may move multiple components between clusters.


\subsection{Bounding the repartition cost.}

In \cite{repartition-disc}, authors trivially bounded the cost of a single reconfiguration 
of \DET
by
$k \cdot \ell$ (the proof is given also in this
manuscript in Theorem~\ref{th:detsqare}).
This roughly corresponds to migrating every node in every cluster, and possibly can be improved.

In \cite{disc2020}, the authors improved the analysis of \DET for
unsaturated edges (that may incur the cost $O(k^2\cdot \ell^2)$).
Precisely, the improved competitive ratio is $O(k\cdot \ell \cdot f(k, \ell))$, where $f(k,
\ell)$ is a bound on the cost of a single repartition.


The best known lower bound for a competitive ratio of any deterministic algorithm is $\Omega(k\cdot \ell)$ \cite{disc2020}.
The best lower bound for a cost of a single repartition is $\Omega(k^3)$.
\maciek{Note to myself: show the $\Omega(k^3)$ costly reconfiguration example}

\medskip

In this manuscript, we state two hypotheses. Proving any of them brings an
immediate improvement to the competitive ratio of \DET.

\begin{hypothesis}\textbf{Strong cascade hypothesis.} The cost of a single
reconfiguration of \DET can be bounded by $f$ that does not depend on $\ell$.
\end{hypothesis}

\begin{hypothesis}
    \textbf{Weak cascade hypothesis.}
The cost of a single reconfiguration of \DET can be bounded by $f$ that is $o(\ell)$ (i.e., the dependency on $\ell$ is
sublinear).
\end{hypothesis}

In both hypotheses, the cost of reconfiguration may be exponential in $k$.
One can think that $k$ is usually small in comparison to $\ell$.

The task is to prove weak and strong cascade hypotheses or provide a
counterexample.



\subsection{Characterization of the migration graph.}


To help analyzing the cost of a reconfiguration, we introduce a \emph{migration graph} that models the reconfiguration.
In the following, we characterize the structure of the migration graph.

\noindent
\textbf{Vertices of the migration graph and the core vertices.}
The vertices of the migration graph are all $\ell$ clusters of the instance.
We distinguish the \emph{core vertices} that correspond to clusters directly involved in the merge operation: the clusters containing the to-be-merged components in $C_I$ and the cluster containing the merged component in $C_F$.
There are at most $3$ core vertices in each migration graph (at most two components participate in the merge, and these may migrate to a third cluster).

\noindent
\textbf{Edges and their labels.}
The edges of the migration graph denote the migration of nodes from $C_I$ to $C_F$.
Each edge is labeled with a set of components that migrate between clusters.
The components are indistinguishable, hence the label is a multiset of component
sizes.
The \emph{weight} of an edge is the sum of sizes of components of its label.
Each edge is directed from the cluster that contained the nodes to the cluster they migrated to.
Both edges might exists between a pair of nodes, as whole components of nodes migrate, and the back-and-forth exchange may be needed for the configuration $C_F$ to be component-respecting.

\noindent
\textbf{Vertex degree.}
At most $k$ nodes may migrate from a cluster and at most $k$ nodes may migrate into a cluster.
Thus, the sum of the labels for both ingoing and outgoing edges of each vertex is at most $k$.
This implies that the number of ingoing and outgoing edges is also bounded by $k$.

\noindent
\textbf{Flow preservation.}
In any configuration (including $C_I$ and $C_F$), each cluster contains exactly $k$ nodes.
Thus, for any vertex, the sum of labels of ingoing edges must equal the sum of labels of outgoing edges.

\noindent
\textbf{Migration graph and the cost of reconfiguration.}
The cost of cluster reconfiguration equals the number of exchanged nodes multiplied by $\alpha$.
From the standpoint of a migration graph, this corresponds to the sum of labels on edges of the graph.
A trivial upper bound on the cost is the size of the connected component in the migration graph multiplied by $2\alpha k$.

\medskip

Note that for a single component merge, multiple migration graphs may exist (it
depends on the choice of the algorithm), and multiple of them might have the optimal cost.

\subsubsection{Rules of the cascade graph optimality}

Flow conservation and degree bounds are the properties of each feasible cascade.
An optimal-cost cascade must have additional properties:
\begin{enumerate}
    \item Shortcutting the intermediate set \maciek{todo}
    \item Shortcutting the cycles \maciek{Is it an instance of the previous one?}
\end{enumerate}

\subsubsection{Cascade graph with full information}

Additional information: for each vertex we have the multiset of its component sizes in its label.

ToDo: search for additional rules that actually imply that each cascade graph with these properties is always the minimum cost reconfiguration.

\section{Tasks}

\subsection{Whiteboard tasks --- Various upper and lower bounds on the cascade.}


Cascade example is an initial configuration of components and a new saturated edge.
We'll search for cascade examples with certain property $P$ of its cascade graphs.
To claim that a cascade example have the property $P$, we must prove $P$ for each minimum cascade graph that leads to a component-respecting partition after saturation.

\begin{task}[Migrate as many singletons as possible]
Show a cascade example with $g(k,l)$ singletons migrating, for as large $g$ as possible (asymptotically).
\end{task}


\begin{task}[The maximum number of migrating singletons.]
Show an upper bound $h(k,l)$ on the number of singletons that can migrate in any cascade.
\end{task}

\begin{task}[Examples for larger components.]
Let $S$ be any of $\{ \Theta(\log(k)), \Theta(\sqrt(k)), \Theta(k)\}$.
Show a cascade example with $g(k,l)$ components of size $S$ migrating.
Show an upper bound $h(k,l)$ on the number of components of size $S$ that can migrate in any cascade.
\end{task}

\begin{task}[Cascade dependency on component sizes.]
Assume all components are of size at most $s$.
Show an upper bound $h(k,l,s)$ on the cost of cascade.
\end{task}

\begin{task}[Cascade dependency on number of saturated edges.]

Let $s$ be a number of saturated edges.
Find the smallest $h(s)$ that bounds the cost of cascade.
\end{task}

\begin{task}[Migrate all sizes of components.]

Show a cascade example where all component sizes ($\{1,2, \ldots, k\}$) migrate.
Show a cascade example where $2$ different components of sizes $1$ and $2$ and $3,\ldots k$ migrate.

Show a cascade example where $\log(k)$ different components of sizes $1, 2, \ldots, \log(k)$ migrate.
\end{task}

\begin{task}[Paths, cycles and ears.]
Show an example of a cascade, where exists a vertex reachable from a core vertex that is not on any simple path (i.e., without repeating vertices) between core vertices.
\end{task}

\begin{task}[Cascade graph example with no 2-edge cycles.]

Show an example of a cascade graph, where each non-core vertex participates only in cycles of length $3$ or more.
\end{task}

\subsection{Programming tasks.}
In this section we propose a number of programming tasks. Their main objective
is to help understanding the problem. Moreover, the tools may be used to quickcheck 
if the cascade graph has certain properties.


\begin{task}[Minimum cost cascade.]

We are given integers $k$, $\ell$, an initial configuration $C_I$ of clusters (the
sizes of components in each cluster), and distinguished components $A$ and
$B$ that are present in the initial configuration.
We say that a configuration is feasible if each component is entirely contained
in a single cluster (i.e., no component is split), and each cluster contains
exactly $k$ nodes.

The objective is to perform a merge operation of $A$ and $B$. Precisely,
\begin{enumerate}
    \item Determine if there exists a feasible configuration of clusters after
        the merge.
    \item Find a feasible configuration that is closest to $C_I$ (the number of
        node migrations is minimized).
    \item If multiple configurations with minimum cost exists, find all of them.
\end{enumerate}

\noindent
\textbf{Implementation.}
Use existing tools such as Mixed-Integer Programming solvers, CP-SAT solvers or
other libraries, specialized in searching spaces of exponential size.
Do not implement your own solutions unless justified.

\noindent The solution must be exponential due to NP-completeness of $\ell$-way integer
partition \cite{AndRae06}.
\subsection{Unique minimum cost cascade.}
Multiple min-cost cascades exists, and many of them may be isomorphic. Propose a
simple rule to determine a unique cascade (e.g. the cascade with components of
minimum index, where index is a component ID). The rule should be easy to
express mathematically and easy to implement.
\end{task}

\begin{task}[Cascade graph analysis.]

Fix a cascade graph, and let $C_F$ be the final configuration.
The \emph{core} vertices of the cascade graph are: the cluster that contains $A$
in $C_I$, the cluster that contains $B$ in $C_I$, and the cluster that contains
$A\cup B$ in $C_F$.

Determine the following properties of the given cascade graph:
\begin{enumerate}
    \item The length of the longest simple cycle (i.e., without repeating
        vertices).
    \item Existence of ears: vertices that do not belong to any simple cycle
        that contains a core vertex.
\end{enumerate}

\end{task}

\begin{task}[Generating initial configurations.]

Automate graph analysis. Generate feasible initial configurations and the
merged pair of components $A$ and $B$. Two
possible solutions:
\begin{enumerate}
    \item Use
random feasible configurations.
\item Enumerate over all possible non-isomorphic configurations for a given small $k$
    and $\ell$.
\end{enumerate}
\end{task}


\section{Julien's adventures with cascade}

\newpage
\subsection{Integer programs that solve 1 request cascade}

\subsubsection{Minimum cost cascade}

We are given two natural numbers $k$ and $\ell$, a set of components $\mathcal{C}$ ($|\mathcal{C}| = m$), and a set of clusters (ToR's) $\mathcal{T}$ ($|\mathcal{T} = \ell$).
We are given and sizes of these components $\mathcal{S} : \mathcal{C} \Rightarrow \mathbb{N}$.
We are given an initial assignment (placement) of components to clusters, i.e., a boolean function $B : \mathcal{C} \times \mathcal{T}$ that is true iff. the component $c \in \mathcal{C}$ is initially in cluster $t \in \mathcal{T}$.
New saturated edge appears between two distinguished components $A, B \in \mathbb{C}$.

The $IP_1$ is formulated as follows.
Let $x_{i,j}$ be a boolean variable that we interpret as if a component $i$ is in the final configuration in cluster $j$.

\[
    \min \sum_{c \in \mathcal{C}} \sum_{t \in \mathcal{T}} (1-B(c, t)) \cdot S(c) \cdot x_{c,t} 
\]
with respect to the following constraints:
\begin{equation}
  \forall_{t\in \mathcal{T}} \sum_{c \in \mathcal{C}} S(c) \cdot x_{c,t} = k
  \label{eq:capacity-constraints-ip1}
\end{equation}
\begin{equation}
    \forall_{c\in \mathcal{C}} \sum_{t \in \mathcal{T}} x_{c,t} = 1
    \label{eq:constraint-single-placement-ip1}
\end{equation}
\begin{equation}
    \forall_{t \in \mathcal{T}} x_{A,t} = x_{B, t}
    \label{eq:constraint-merge-ip1}
\end{equation}
\begin{equation}
    \forall_{c\in \mathcal{C}} \forall_{t\in \mathcal{T}} x_{c, t} \in \{ 0, 1 \}
\end{equation}


We interpret the constraints in the following way: \ref{eq:capacity-constraints-ip1}  means that the capacity of clusters must by obeyed, \ref{eq:constraint-single-placement-ip1} means that each component can be at one cluster in the final configuration, \ref{eq:constraint-merge-ip1} means that distinguished components $A$ and $B$ are collocated.

\subsubsection{Closest to initial cascade}

\subsubsection{Closest to initial cascade and among them, the cheapest}

\subsubsection{Minimum cascade and among them, the closest to initial configuration}

\subsubsection{Per-node IP for closest to initial cascade}

Variable $y_{n,t}$

\subsection{Costly cascades}

\subsubsection{k/2 cost cascade with at most sqrt size of components}

\subsubsection{$O(k^2)$ cost cascade for $\ell$ servers}

\subsection{k log k cost of a phase hypothesis for two servers}

- full cost model

\bibliographystyle{alpha}  
\bibliography{references}  


\appendix


\end{document}
